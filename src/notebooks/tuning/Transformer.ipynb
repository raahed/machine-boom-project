{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68428bb911200c6d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model 3: Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bf9c828b972fb25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T08:49:41.383530200Z",
     "start_time": "2023-11-08T08:49:38.315132700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0d27e318ab2d0a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T08:49:45.938428800Z",
     "start_time": "2023-11-08T08:49:45.925429400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '/mnt/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transformer import TransformerEncoderModel, train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5626b225d0d87d10",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create Trajectory dataset from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35127225b7572d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T08:50:37.088191200Z",
     "start_time": "2023-11-08T08:50:36.916190Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils.file_io import read_trajectory_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70433f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'left_boom_base_yaw_joint', \n",
    "    'left_boom_base_pitch_joint',\n",
    "    'left_boom_main_prismatic_joint',\n",
    "    'left_boom_second_roll_joint',\n",
    "    'left_boom_second_yaw_joint',\n",
    "    'left_boom_top_pitch_joint',\n",
    "    'left_boom_ee_joint',\n",
    "    'cable1_property(length,youngsmodule(bend,twist))',\n",
    "    'cable2_property(length,youngsmodule(bend,twist))',\n",
    "    'cable3_property(length,youngsmodule(bend,twist))'\n",
    "]\n",
    "\n",
    "label_features = [\n",
    "    ('cable1_lowest_point', np.array([1], dtype=np.int64)),\n",
    "    ('cable2_lowest_point', np.array([1], dtype=np.int64)),\n",
    "    ('cable3_lowest_point', np.array([1], dtype=np.int64))\n",
    "]\n",
    "\n",
    "normalized_features = [\n",
    "    ('cable1_property(length,youngsmodule(bend,twist))', np.array([1,2], dtype=np.int64)),\n",
    "    ('cable2_property(length,youngsmodule(bend,twist))', np.array([1,2], dtype=np.int64)),\n",
    "    ('cable3_property(length,youngsmodule(bend,twist))', np.array([1,2], dtype=np.int64))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132f29ad39f9351a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-08T08:50:49.359883400Z",
     "start_time": "2023-11-08T08:50:38.050809600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading .csv files: 1it [00:00,  2.53it/s]\n",
      "/mnt/src/notebooks/../utils/preprocessing.py:132: RuntimeWarning: divide by zero encountered in divide\n",
      "  return np.where(x_max != x_min, (features - x_min) / (x_max - x_min), 1).astype(dtype=np.float32)\n",
      "/mnt/src/notebooks/../utils/preprocessing.py:132: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.where(x_max != x_min, (features - x_min) / (x_max - x_min), 1).astype(dtype=np.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataframe\n",
      "Reshaping dataframe for learning\n"
     ]
    }
   ],
   "source": [
    "data_folder = Path(\"/mnt/data\").absolute()\n",
    "train_set, _, validation_set, _ = read_trajectory_datasets(data_folder, 0.8, 0, 0.2, window_size=256, \n",
    "                                                                  feature_columns=feature_columns, label_features=label_features, \n",
    "                                                                  normalized_features=normalized_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape 16 / 3 of total 40 data rows!\n"
     ]
    }
   ],
   "source": [
    "input_shape, output_shape = 16, 3\n",
    "print(f\"Data shape {input_shape} / {output_shape} of total {len(train_set) + len(validation_set)} data rows!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load parameter, functions and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_path = Path(\"/mnt/models/transformer/tune\").absolute()\n",
    "tune_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with optuna hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb20a74562832db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune, train as ray_train\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from torch import nn\n",
    "from typing import Dict\n",
    "from utils.cluster import attach_ray, disconnect_ray\n",
    "from utils.optimizer import get_optimizer_function, get_learning_rate_scheduler\n",
    "from utils.activation import get_activation\n",
    "from utils.loss_functions import get_loss_function\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random; random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_train(parameter: Dict, train_epochs: int, train_set: Dataset, validation_set: Dataset, model_input_shape: int,\n",
    "                    model_output_shape: int) -> None:\n",
    "\n",
    "    # Determ device on the actual worker used for the trail\n",
    "    device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    if device != \"cuda\":\n",
    "        print(\"No cuda device found!\")\n",
    "\n",
    "    train_dataloader = DataLoader(train_set, batch_size=parameter[\"batch_size\"], shuffle = True)\n",
    "    validation_dataloader = DataLoader(validation_set, batch_size=parameter[\"batch_size\"], shuffle = True)\n",
    "\n",
    "    activation = get_activation(parameter[\"activation\"])\n",
    "\n",
    "    model = TransformerEncoderModel(\n",
    "        num_heads = parameter[\"model_dim_num_heads_projection\"][1],\n",
    "        model_dim = parameter[\"model_dim_num_heads_projection\"][0],\n",
    "        feedforward_hidden_dim = parameter[\"feedforward_dim\"],\n",
    "        num_encoder_layers = parameter[\"num_encoder_layer\"],\n",
    "        output_dim = model_output_shape,\n",
    "        transformer_dropout = parameter[\"transformer_dropout\"],\n",
    "        pos_encoder_dropout = parameter[\"pos_encoder_dropout\"],\n",
    "        downprojection = True if parameter[\"model_dim_num_heads_projection\"][2] != 0 else False,\n",
    "        projection_num_neighbors = parameter[\"model_dim_num_heads_projection\"][2],\n",
    "        activation = activation\n",
    "    )\n",
    "\n",
    "    # The model needs to be on the device used for training before instance the optimizer\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = get_optimizer_function(parameter[\"optimizer\"], model, 1)\n",
    "    lr_scheduler = get_learning_rate_scheduler(optimizer, parameter[\"model_dim\"], parameter[\"warmup_steps\"])\n",
    "    loss_function = get_loss_function()\n",
    "\n",
    "    _ = train(train_epochs, train_dataloader, validation_dataloader, model, loss_function, optimizer, lr_scheduler, None, device, report_interval=50, tune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 2000\n",
    "num_epochs = 750\n",
    "grace_period = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "926a9b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dim_params = []\n",
    "\n",
    "n_neighbors = [3, 5, 7, 10, 15]\n",
    "model_dim = [input_shape, output_shape]\n",
    "\n",
    "for d in model_dim:\n",
    "    num_heads = []\n",
    "    for i in range(2, d + 1):\n",
    "        if d % i == 0: num_heads.append(i)\n",
    "\n",
    "    for h in num_heads:\n",
    "\n",
    "        if d != output_shape:\n",
    "            model_dim_params.append((d, h, 0))\n",
    "        else:\n",
    "            for n in n_neighbors:\n",
    "                model_dim_params.append((d, h, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad30e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = np.log2(256), np.log2(2048)\n",
    "num_values = 10\n",
    "feedforward_dim = [int(2 ** (start + i / (num_values - 1) * (end - start))) for i in range(num_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    \"pos_encoder_dropout\": tune.loguniform(0.05, 0.6, base = 2),\n",
    "    \"transformer_dropout\": tune.loguniform(0.05, 0.6, base = 2),\n",
    "    \"num_encoder_layer\": tune.choice(list(range(2, 10 + 1, 2))),\n",
    "    \"feedforward_dim\": tune.choice(feedforward_dim),\n",
    "    \"batch_size\": tune.choice(list(range(64, 256, 16))),\n",
    "    \n",
    "    \"model_dim_num_heads_projection\": tune.choice(model_dim_params),\n",
    "    \"optimizer\": tune.choice([\"adam\", \"adamw\"]),\n",
    "    \"activation\": tune.choice([\"relu\", \"gelu\"]),\n",
    "    \"warmup_steps\": tune.choice(list(range(1000, 4000, 200))),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = ASHAScheduler(\n",
    "    metric = \"loss\",\n",
    "    mode = \"min\",\n",
    "    max_t = num_epochs,\n",
    "    grace_period = grace_period\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_alg = OptunaSearch(\n",
    "    metric = \"loss\",\n",
    "    mode = \"min\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 16:48:55,263\tINFO worker.py:1673 -- Started a local Ray instance.\n",
      "2023-12-12 16:48:55,449\tINFO packaging.py:530 -- Creating a file package for local directory '/mnt/src/notebooks/../utils'.\n",
      "2023-12-12 16:48:55,714\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_a350e7b4e294648b.zip' (0.07MiB) to Ray cluster...\n",
      "2023-12-12 16:48:55,716\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_a350e7b4e294648b.zip'.\n",
      "2023-12-12 16:48:55,798\tINFO packaging.py:530 -- Creating a file package for local directory '/mnt/src/models'.\n",
      "2023-12-12 16:48:55,906\tINFO packaging.py:358 -- Pushing file package 'gcs://_ray_pkg_6289afc7074cc6ea.zip' (0.03MiB) to Ray cluster...\n",
      "2023-12-12 16:48:55,907\tINFO packaging.py:371 -- Successfully pushed file package 'gcs://_ray_pkg_6289afc7074cc6ea.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hostname': 'md3zx1nc-mbp-runner', 'resources': {'node:__internal_head__': 1.0, 'CPU': 8.0, 'object_store_memory': 4475621376.0, 'node:172.17.0.2': 1.0, 'memory': 8951242752.0}}\n"
     ]
    }
   ],
   "source": [
    "attach_ray(manager = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_resources_manager = tune.with_resources(\n",
    "    trainable=lambda param: parameter_train(param, num_epochs, train_set, validation_set, input_shape, output_shape),\n",
    "    # See: https://stackoverflow.com/questions/58967793/what-is-the-way-to-make-tune-run-parallel-trials-across-multiple-gpus\n",
    "    resources={ \"cpu\": 3, \"gpu\": 0.25 if torch.cuda.is_available() else 0 }\n",
    ")\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    ray_resources_manager,\n",
    "    param_space=parameter_space,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        scheduler=scheduler,\n",
    "        search_alg=search_alg,\n",
    "         num_samples=num_samples\n",
    "    ),\n",
    "    run_config = ray_train.RunConfig(\n",
    "        name = \"transformer_encoder\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-12-12 16:49:23</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:26.31        </td></tr>\n",
       "<tr><td>Memory:      </td><td>3.7/15.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 320.000: None | Iter 80.000: None | Iter 20.000: None | Iter 5.000: None<br>Logical resource usage: 3.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 2<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name     </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_f9aa04c7</td><td style=\"text-align: right;\">           1</td><td>/root/ray_results/transformer_encoder/lambda_f9aa04c7_1_activation=relu,batch_size=208,feedforward_dim=322,model_dim_num_heads_projection=3_3_15,num_encoder_layer=6,opt_2023-12-12_16-48-57/error.txt</td></tr>\n",
       "<tr><td>lambda_5a89ee19</td><td style=\"text-align: right;\">           1</td><td>/root/ray_results/transformer_encoder/lambda_5a89ee19_2_activation=relu,batch_size=112,feedforward_dim=1625,model_dim_num_heads_projection=3_3_15,num_encoder_layer=4,op_2023-12-12_16-49-07/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name     </th><th>status  </th><th>loc             </th><th>activation  </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">  feedforward_dim</th><th>model_dim_num_heads_\n",
       "projection           </th><th style=\"text-align: right;\">  num_encoder_layer</th><th>optimizer  </th><th style=\"text-align: right;\">  pos_encoder_dropout</th><th style=\"text-align: right;\">  transformer_dropout</th><th style=\"text-align: right;\">  warmup_steps</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_d877e8cf</td><td>PENDING </td><td>                </td><td>gelu        </td><td style=\"text-align: right;\">          80</td><td style=\"text-align: right;\">             2048</td><td>(3, 3, 7) </td><td style=\"text-align: right;\">                  6</td><td>adamw      </td><td style=\"text-align: right;\">            0.217021 </td><td style=\"text-align: right;\">            0.221131 </td><td style=\"text-align: right;\">          3200</td></tr>\n",
       "<tr><td>lambda_f9aa04c7</td><td>ERROR   </td><td>172.17.0.2:23099</td><td>relu        </td><td style=\"text-align: right;\">         208</td><td style=\"text-align: right;\">              322</td><td>(3, 3, 15)</td><td style=\"text-align: right;\">                  6</td><td>adamw      </td><td style=\"text-align: right;\">            0.0615668</td><td style=\"text-align: right;\">            0.0540211</td><td style=\"text-align: right;\">          3000</td></tr>\n",
       "<tr><td>lambda_5a89ee19</td><td>ERROR   </td><td>172.17.0.2:23163</td><td>relu        </td><td style=\"text-align: right;\">         112</td><td style=\"text-align: right;\">             1625</td><td>(3, 3, 15)</td><td style=\"text-align: right;\">                  4</td><td>adam       </td><td style=\"text-align: right;\">            0.137261 </td><td style=\"text-align: right;\">            0.146587 </td><td style=\"text-align: right;\">          3800</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=23099)\u001b[0m No cuda device found!\n",
      "\u001b[36m(<lambda> pid=23099)\u001b[0m torch.Size([1024, 3])\n",
      "\u001b[36m(<lambda> pid=23099)\u001b[0m torch.Size([2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=23099)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "\u001b[36m(<lambda> pid=23099)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "2023-12-12 16:49:07,223\tERROR tune_controller.py:1383 -- Trial task failed for trial lambda_f9aa04c7\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(IndexError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=23099, ip=172.17.0.2, actor_id=d1f555bc09e7acbfeacd8c4401000000, repr=<lambda>)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 91, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_22729/1950268357.py\", line 2, in <lambda>\n",
      "  File \"/tmp/ipykernel_22729/2000386134.py\", line 15, in parameter_train\n",
      "  File \"/tmp/ray/session_2023-12-12_16-48-52_322778_22729/runtime_resources/py_modules_files/_ray_pkg_6289afc7074cc6ea/models/transformer.py\", line 53, in __init__\n",
      "    self.pos_encoder = PositionalEncoding(model_dim, pos_encoder_dropout)\n",
      "  File \"/tmp/ray/session_2023-12-12_16-48-52_322778_22729/runtime_resources/py_modules_files/_ray_pkg_6289afc7074cc6ea/models/transformer.py\", line 26, in __init__\n",
      "    pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
      "IndexError: too many indices for tensor of dimension 2\n",
      "\u001b[36m(<lambda> pid=23163)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "\u001b[36m(<lambda> pid=23163)\u001b[0m   warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "2023-12-12 16:49:15,455\tERROR tune_controller.py:1383 -- Trial task failed for trial lambda_5a89ee19\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 24, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2563, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(IndexError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=23163, ip=172.17.0.2, actor_id=f32c91323d679d89ac42795001000000, repr=<lambda>)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 342, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 91, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 115, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 332, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/tmp/ipykernel_22729/1950268357.py\", line 2, in <lambda>\n",
      "  File \"/tmp/ipykernel_22729/2000386134.py\", line 15, in parameter_train\n",
      "  File \"/tmp/ray/session_2023-12-12_16-48-52_322778_22729/runtime_resources/py_modules_files/_ray_pkg_6289afc7074cc6ea/models/transformer.py\", line 53, in __init__\n",
      "    self.pos_encoder = PositionalEncoding(model_dim, pos_encoder_dropout)\n",
      "  File \"/tmp/ray/session_2023-12-12_16-48-52_322778_22729/runtime_resources/py_modules_files/_ray_pkg_6289afc7074cc6ea/models/transformer.py\", line 26, in __init__\n",
      "    pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
      "IndexError: too many indices for tensor of dimension 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=23163)\u001b[0m No cuda device found!\n",
      "\u001b[36m(<lambda> pid=23163)\u001b[0m torch.Size([2])\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 16:49:23,864\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-12-12 16:49:24,030\tERROR tune.py:1043 -- Trials did not complete: [lambda_f9aa04c7, lambda_5a89ee19]\n",
      "2023-12-12 16:49:24,031\tINFO tune.py:1047 -- Total run time: 26.70 seconds (26.30 seconds for the tuning loop).\n",
      "2023-12-12 16:49:24,033\tWARNING tune.py:1062 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/root/ray_results/transformer_encoder\", trainable=...)\n",
      "2023-12-12 16:49:24,051\tWARNING experiment_analysis.py:185 -- Failed to fetch metrics for 1 trial(s):\n",
      "- lambda_d877e8cf: FileNotFoundError('Could not fetch metrics for lambda_d877e8cf: both result.json and progress.csv were not found at /root/ray_results/transformer_encoder/lambda_d877e8cf_3_activation=gelu,batch_size=80,feedforward_dim=2048,model_dim_num_heads_projection=3_3_7,num_encoder_layer=6,opti_2023-12-12_16-49-15')\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disconnect_ray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv file\n",
    "result_grid = results.get_dataframe()\n",
    "result_grid.to_csv(tune_path / \"trail_grid_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = result_grid.iloc[result_grid['loss'].idxmin()].to_dict()\n",
    "trail_id = best_result['trial_id']\n",
    "\n",
    "print(f\"Trail ID from the best run: {trail_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best trail by loss value {best_result['loss']}\", \"\\n------\")\n",
    "for key in best_result:\n",
    "    if 'config' in key:\n",
    "        print(f\"Best trail: {key} value {best_result[key]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
