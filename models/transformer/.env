# Training Hyperparameters
BATCH_SIZE=64
OPTIMIZER=adam
ACTIVATION=relu
NUM_ENCODER_LAYER=8
POS_ENCODER_DROPOUT=0.245363862640934
TRANSFORMER_DROPOUT=0.342685818
FEEDFORWARD_DIM=1625
WARMUP_STEPS=1000
MODEL_DIM_NUM_HEADS_PROJECTION=(16, 2, 0)
NUM_EPOCHS=1000